{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Posts Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape data from the reddit, first of all you need to validate your self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:46:32.510470Z",
     "start_time": "2020-08-28T19:46:30.674263Z"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:46:32.542655Z",
     "start_time": "2020-08-28T19:46:32.529254Z"
    }
   },
   "outputs": [],
   "source": [
    "# chenge this\n",
    "my_client_id = 'Personal_Use_Script'\n",
    "my_client_secret = 'Client_Secret_Key'\n",
    "my_user_agent = 'Reddit_App_Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:46:32.577126Z",
     "start_time": "2020-08-28T19:46:32.566370Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=my_client_id, \\\n",
    "                     client_secret=my_client_secret, \\\n",
    "                     user_agent=my_user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:46:32.595551Z",
     "start_time": "2020-08-28T19:46:32.584700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = {\"title\":[], \"id\":[], \"redditor\":[], \"num_upvotes\":[], \\\n",
    "             \"subreddit\":[], \"url\":[], \"num_comments\": [],\\\n",
    "             \"created_on\": [], \"body\":[], \"upvote_ratio\":[], \"over_18\":[],\\\n",
    "             \"link_flair_text\":[], \"edited\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:46:32.619544Z",
     "start_time": "2020-08-28T19:46:32.602075Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_posts(subreddit_name):\n",
    "    subreddit= reddit.subreddit(subreddit_name).top(limit=1000)\n",
    "    for submission in subreddit:\n",
    "        data_dict[\"title\"].append(submission.title)\n",
    "        data_dict[\"num_upvotes\"].append(submission.score)\n",
    "        data_dict[\"id\"].append(submission.id)\n",
    "        data_dict[\"subreddit\"].append(submission.subreddit)\n",
    "        data_dict[\"url\"].append(submission.url)\n",
    "        data_dict[\"num_comments\"].append(submission.num_comments)\n",
    "        data_dict[\"created_on\"].append(submission.created)\n",
    "        data_dict[\"body\"].append(submission.selftext)\n",
    "        data_dict[\"upvote_ratio\"].append(submission.upvote_ratio)\n",
    "        data_dict[\"over_18\"].append(submission.over_18)\n",
    "        data_dict[\"link_flair_text\"].append(submission.link_flair_text)\n",
    "        data_dict[\"edited\"].append(submission.edited)\n",
    "        data_dict[\"redditor\"].append(submission.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:46:32.634144Z",
     "start_time": "2020-08-28T19:46:32.624957Z"
    }
   },
   "outputs": [],
   "source": [
    "subreddits= ['datascience', 'MachineLearning', 'learnmachinelearning', \n",
    "             'LanguageTechnology', 'deeplearning', 'datasets', 'visualization',\n",
    "             'dataisbeautiful', 'learnpython', 'MLQuestions', 'DataVizRequests',\n",
    "             'statistics', 'SQL', 'neuralnetworks', 'mlpapers', 'MachinesLearn',\n",
    "             'datacleaning', 'artificial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:51:36.494357Z",
     "start_time": "2020-08-28T19:46:32.640728Z"
    }
   },
   "outputs": [],
   "source": [
    "for subreddit in subreddits:\n",
    "    get_posts(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:51:36.985354Z",
     "start_time": "2020-08-28T19:51:36.504596Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:51:37.253171Z",
     "start_time": "2020-08-28T19:51:37.078303Z"
    }
   },
   "outputs": [],
   "source": [
    "data['created_on'] = data['created_on'].apply(lambda x: dt.datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T19:51:37.438342Z",
     "start_time": "2020-08-28T19:51:37.294886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>redditor</th>\n",
       "      <th>num_upvotes</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_on</th>\n",
       "      <th>body</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>over_18</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Itâ€™s never too early</td>\n",
       "      <td>fg73za</td>\n",
       "      <td>da_chosen1</td>\n",
       "      <td>2895</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/0c9louclfrl41.jpg</td>\n",
       "      <td>58</td>\n",
       "      <td>2020-03-10 16:26:29</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shout Out to All the Mediocre Data Scientists ...</td>\n",
       "      <td>hohvgq</td>\n",
       "      <td>MrBurritoQuest</td>\n",
       "      <td>2652</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>263</td>\n",
       "      <td>2020-07-10 17:15:31</td>\n",
       "      <td>I've been lurking on this sub for a while now ...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imposter Syndrome is a problem for me and I th...</td>\n",
       "      <td>e6iy5o</td>\n",
       "      <td>ExecutiveFingerblast</td>\n",
       "      <td>2497</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/e292g50m4u241.jpg</td>\n",
       "      <td>136</td>\n",
       "      <td>2019-12-06 05:16:05</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True that</td>\n",
       "      <td>ejvao9</td>\n",
       "      <td>None</td>\n",
       "      <td>2310</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/vh0ey1fgsm841.jpg</td>\n",
       "      <td>227</td>\n",
       "      <td>2020-01-05 00:23:50</td>\n",
       "      <td></td>\n",
       "      <td>0.97</td>\n",
       "      <td>False</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graph of graph analysis</td>\n",
       "      <td>frkgr7</td>\n",
       "      <td>VeryOddEvey</td>\n",
       "      <td>2223</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/m99e3svtpqp41.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>2020-03-30 18:17:40</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15929</th>\n",
       "      <td>Artificial Intelligence War Between The U.S. A...</td>\n",
       "      <td>cabj69</td>\n",
       "      <td>newworld-ai</td>\n",
       "      <td>54</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://www.newworldai.com/artificial-intellig...</td>\n",
       "      <td>16</td>\n",
       "      <td>2019-07-08 09:57:54</td>\n",
       "      <td></td>\n",
       "      <td>0.88</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15930</th>\n",
       "      <td>Making AI more human is key to widespread acce...</td>\n",
       "      <td>c47cmv</td>\n",
       "      <td>Chipdoc</td>\n",
       "      <td>53</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://uwaterloo.ca/math/news/making-ai-more-...</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-06-24 06:05:32</td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>AI Restores Photos of â€™90s Hong Kong Film Stars</td>\n",
       "      <td>buvczb</td>\n",
       "      <td>Yuqing7</td>\n",
       "      <td>50</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://medium.com/syncedreview/ai-restores-ph...</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-31 06:09:20</td>\n",
       "      <td></td>\n",
       "      <td>0.93</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15932</th>\n",
       "      <td>I/O 2019 | Your Data Stays on Your Phone: Goog...</td>\n",
       "      <td>blyrbf</td>\n",
       "      <td>Yuqing7</td>\n",
       "      <td>54</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://medium.com/syncedreview/i-o-2019-your-...</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-05-08 14:18:50</td>\n",
       "      <td></td>\n",
       "      <td>0.93</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15933</th>\n",
       "      <td>Japan aims to produce 250,000 AI experts a year</td>\n",
       "      <td>b7yql0</td>\n",
       "      <td>shaunlgs</td>\n",
       "      <td>53</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://asia.nikkei.com/Economy/Japan-aims-to-...</td>\n",
       "      <td>11</td>\n",
       "      <td>2019-04-01 20:31:45</td>\n",
       "      <td></td>\n",
       "      <td>0.89</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15934 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      id  \\\n",
       "0                                   Itâ€™s never too early  fg73za   \n",
       "1      Shout Out to All the Mediocre Data Scientists ...  hohvgq   \n",
       "2      Imposter Syndrome is a problem for me and I th...  e6iy5o   \n",
       "3                                              True that  ejvao9   \n",
       "4                                Graph of graph analysis  frkgr7   \n",
       "...                                                  ...     ...   \n",
       "15929  Artificial Intelligence War Between The U.S. A...  cabj69   \n",
       "15930  Making AI more human is key to widespread acce...  c47cmv   \n",
       "15931    AI Restores Photos of â€™90s Hong Kong Film Stars  buvczb   \n",
       "15932  I/O 2019 | Your Data Stays on Your Phone: Goog...  blyrbf   \n",
       "15933    Japan aims to produce 250,000 AI experts a year  b7yql0   \n",
       "\n",
       "                   redditor  num_upvotes    subreddit  \\\n",
       "0                da_chosen1         2895  datascience   \n",
       "1            MrBurritoQuest         2652  datascience   \n",
       "2      ExecutiveFingerblast         2497  datascience   \n",
       "3                      None         2310  datascience   \n",
       "4               VeryOddEvey         2223  datascience   \n",
       "...                     ...          ...          ...   \n",
       "15929           newworld-ai           54   artificial   \n",
       "15930               Chipdoc           53   artificial   \n",
       "15931               Yuqing7           50   artificial   \n",
       "15932               Yuqing7           54   artificial   \n",
       "15933              shaunlgs           53   artificial   \n",
       "\n",
       "                                                     url  num_comments  \\\n",
       "0                    https://i.redd.it/0c9louclfrl41.jpg            58   \n",
       "1      https://www.reddit.com/r/datascience/comments/...           263   \n",
       "2                    https://i.redd.it/e292g50m4u241.jpg           136   \n",
       "3                    https://i.redd.it/vh0ey1fgsm841.jpg           227   \n",
       "4                    https://i.redd.it/m99e3svtpqp41.jpg            43   \n",
       "...                                                  ...           ...   \n",
       "15929  https://www.newworldai.com/artificial-intellig...            16   \n",
       "15930  https://uwaterloo.ca/math/news/making-ai-more-...             6   \n",
       "15931  https://medium.com/syncedreview/ai-restores-ph...             3   \n",
       "15932  https://medium.com/syncedreview/i-o-2019-your-...            10   \n",
       "15933  https://asia.nikkei.com/Economy/Japan-aims-to-...            11   \n",
       "\n",
       "               created_on                                               body  \\\n",
       "0     2020-03-10 16:26:29                                                      \n",
       "1     2020-07-10 17:15:31  I've been lurking on this sub for a while now ...   \n",
       "2     2019-12-06 05:16:05                                                      \n",
       "3     2020-01-05 00:23:50                                                      \n",
       "4     2020-03-30 18:17:40                                                      \n",
       "...                   ...                                                ...   \n",
       "15929 2019-07-08 09:57:54                                                      \n",
       "15930 2019-06-24 06:05:32                                                      \n",
       "15931 2019-05-31 06:09:20                                                      \n",
       "15932 2019-05-08 14:18:50                                                      \n",
       "15933 2019-04-01 20:31:45                                                      \n",
       "\n",
       "       upvote_ratio  over_18 link_flair_text edited  \n",
       "0              0.98    False            None  False  \n",
       "1              0.98    False      Discussion  False  \n",
       "2              0.98    False            None  False  \n",
       "3              0.97    False      Fun/Trivia  False  \n",
       "4              0.98    False      Fun/Trivia  False  \n",
       "...             ...      ...             ...    ...  \n",
       "15929          0.88    False            None  False  \n",
       "15930          0.85    False            None  False  \n",
       "15931          0.93    False            None  False  \n",
       "15932          0.93    False            None  False  \n",
       "15933          0.89    False            None  False  \n",
       "\n",
       "[15934 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T20:02:08.653527Z",
     "start_time": "2020-08-28T20:02:08.389663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past reddit posts: (15932, 13)\n"
     ]
    }
   ],
   "source": [
    "reddit_old_data = pd.read_csv(\"machine_learning_and_data_science_subreddit_data.csv\")\n",
    "print(f\"past reddit posts: {reddit_old_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T20:02:24.238546Z",
     "start_time": "2020-08-28T20:02:24.169085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new reddit posts: 15934 past reddit posts: 15932 all reddit posts: 31866\n"
     ]
    }
   ],
   "source": [
    "reddit_all_df = pd.concat([reddit_old_data, data], axis=0)\n",
    "print(f\"new reddit posts: {data.shape[0]} past reddit posts: {reddit_old_data.shape[0]} all reddit posts: {reddit_all_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T20:02:27.407250Z",
     "start_time": "2020-08-28T20:02:26.994725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all reddit posts: (31866, 13)\n"
     ]
    }
   ],
   "source": [
    "reddit_all_df.drop_duplicates(subset = [\"title\", \"id\", \"redditor\", \"subreddit\"], inplace=True)\n",
    "print(f\"all reddit posts: {reddit_all_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T20:02:51.921697Z",
     "start_time": "2020-08-28T20:02:49.994902Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit_all_df.to_csv('machine_learning_and_data_science_subreddit_data.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
