{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Posts Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape data from the reddit, first of all you need to validate your self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:16:23.060431Z",
     "start_time": "2020-08-25T10:16:21.076124Z"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:16:23.075415Z",
     "start_time": "2020-08-25T10:16:23.065264Z"
    }
   },
   "outputs": [],
   "source": [
    "# chenge this\n",
    "my_client_id = 'Personal_Use_Script'\n",
    "my_client_secret = 'Client_Secret_Key'\n",
    "my_user_agent = 'Reddit_App_Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:16:23.091827Z",
     "start_time": "2020-08-25T10:16:23.080325Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=my_client_id, \\\n",
    "                     client_secret=my_client_secret, \\\n",
    "                     user_agent=my_user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:16:23.105633Z",
     "start_time": "2020-08-25T10:16:23.096323Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = {\"title\":[], \"id\":[], \"redditor\":[], \"num_upvotes\":[], \\\n",
    "             \"subreddit\":[], \"url\":[], \"num_comments\": [],\\\n",
    "             \"created_on\": [], \"body\":[], \"upvote_ratio\":[], \"over_18\":[],\\\n",
    "             \"link_flair_text\":[], \"edited\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:16:23.119696Z",
     "start_time": "2020-08-25T10:16:23.109074Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_posts(subreddit_name):\n",
    "    subreddit= reddit.subreddit(subreddit_name).top(limit=1000)\n",
    "    for submission in subreddit:\n",
    "        data_dict[\"title\"].append(submission.title)\n",
    "        data_dict[\"num_upvotes\"].append(submission.score)\n",
    "        data_dict[\"id\"].append(submission.id)\n",
    "        data_dict[\"subreddit\"].append(submission.subreddit)\n",
    "        data_dict[\"url\"].append(submission.url)\n",
    "        data_dict[\"num_comments\"].append(submission.num_comments)\n",
    "        data_dict[\"created_on\"].append(submission.created)\n",
    "        data_dict[\"body\"].append(submission.selftext)\n",
    "        data_dict[\"upvote_ratio\"].append(submission.upvote_ratio)\n",
    "        data_dict[\"over_18\"].append(submission.over_18)\n",
    "        data_dict[\"link_flair_text\"].append(submission.link_flair_text)\n",
    "        data_dict[\"edited\"].append(submission.edited)\n",
    "        data_dict[\"redditor\"].append(submission.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:16:23.130872Z",
     "start_time": "2020-08-25T10:16:23.123207Z"
    }
   },
   "outputs": [],
   "source": [
    "subreddits= ['datascience', 'MachineLearning', 'learnmachinelearning', \n",
    "             'LanguageTechnology', 'deeplearning', 'datasets', 'visualization',\n",
    "             'dataisbeautiful', 'learnpython', 'MLQuestions', 'DataVizRequests',\n",
    "             'statistics', 'SQL', 'neuralnetworks', 'mlpapers', 'MachinesLearn',\n",
    "             'datacleaning', 'artificial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:25:28.670523Z",
     "start_time": "2020-08-25T10:16:23.135145Z"
    }
   },
   "outputs": [],
   "source": [
    "for subreddit in subreddits:\n",
    "    get_posts(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:25:28.760184Z",
     "start_time": "2020-08-25T10:25:28.677003Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:25:28.813384Z",
     "start_time": "2020-08-25T10:25:28.768948Z"
    }
   },
   "outputs": [],
   "source": [
    "data['created_on'] = data['created_on'].apply(lambda x: dt.datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:25:28.908961Z",
     "start_time": "2020-08-25T10:25:28.819444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>redditor</th>\n",
       "      <th>num_upvotes</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_on</th>\n",
       "      <th>body</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>over_18</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It’s never too early</td>\n",
       "      <td>fg73za</td>\n",
       "      <td>da_chosen1</td>\n",
       "      <td>2892</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/0c9louclfrl41.jpg</td>\n",
       "      <td>58</td>\n",
       "      <td>2020-03-10 16:26:29</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shout Out to All the Mediocre Data Scientists ...</td>\n",
       "      <td>hohvgq</td>\n",
       "      <td>MrBurritoQuest</td>\n",
       "      <td>2638</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>262</td>\n",
       "      <td>2020-07-10 17:15:31</td>\n",
       "      <td>I've been lurking on this sub for a while now ...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imposter Syndrome is a problem for me and I th...</td>\n",
       "      <td>e6iy5o</td>\n",
       "      <td>ExecutiveFingerblast</td>\n",
       "      <td>2498</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/e292g50m4u241.jpg</td>\n",
       "      <td>136</td>\n",
       "      <td>2019-12-06 05:16:05</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True that</td>\n",
       "      <td>ejvao9</td>\n",
       "      <td>None</td>\n",
       "      <td>2313</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/vh0ey1fgsm841.jpg</td>\n",
       "      <td>227</td>\n",
       "      <td>2020-01-05 00:23:50</td>\n",
       "      <td></td>\n",
       "      <td>0.97</td>\n",
       "      <td>False</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graph of graph analysis</td>\n",
       "      <td>frkgr7</td>\n",
       "      <td>VeryOddEvey</td>\n",
       "      <td>2226</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/m99e3svtpqp41.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>2020-03-30 18:17:40</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15927</th>\n",
       "      <td>I/O 2019 | Your Data Stays on Your Phone: Goog...</td>\n",
       "      <td>blyrbf</td>\n",
       "      <td>Yuqing7</td>\n",
       "      <td>50</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://medium.com/syncedreview/i-o-2019-your-...</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-05-08 14:18:50</td>\n",
       "      <td></td>\n",
       "      <td>0.91</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15928</th>\n",
       "      <td>Japan aims to produce 250,000 AI experts a year</td>\n",
       "      <td>b7yql0</td>\n",
       "      <td>shaunlgs</td>\n",
       "      <td>53</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://asia.nikkei.com/Economy/Japan-aims-to-...</td>\n",
       "      <td>11</td>\n",
       "      <td>2019-04-01 20:31:45</td>\n",
       "      <td></td>\n",
       "      <td>0.88</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15929</th>\n",
       "      <td>Why AI progress is faster than Moore’s Law — t...</td>\n",
       "      <td>b229a0</td>\n",
       "      <td>caternoon</td>\n",
       "      <td>53</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://hackernoon.com/the-age-of-the-algorith...</td>\n",
       "      <td>39</td>\n",
       "      <td>2019-03-17 19:40:56</td>\n",
       "      <td></td>\n",
       "      <td>0.90</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15930</th>\n",
       "      <td>Introducing GPipe, an Open Source Library for ...</td>\n",
       "      <td>azh242</td>\n",
       "      <td>WebHostingSaver</td>\n",
       "      <td>54</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://ai.googleblog.com/2019/03/introducing-...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-11 05:31:48</td>\n",
       "      <td></td>\n",
       "      <td>0.93</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>AI is not “magic dust” for your company, says ...</td>\n",
       "      <td>9vkwbw</td>\n",
       "      <td>mr_j_b</td>\n",
       "      <td>53</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://www.technologyreview.com/s/612394/ai-i...</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-11-10 04:03:24</td>\n",
       "      <td></td>\n",
       "      <td>0.88</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15932 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      id  \\\n",
       "0                                   It’s never too early  fg73za   \n",
       "1      Shout Out to All the Mediocre Data Scientists ...  hohvgq   \n",
       "2      Imposter Syndrome is a problem for me and I th...  e6iy5o   \n",
       "3                                              True that  ejvao9   \n",
       "4                                Graph of graph analysis  frkgr7   \n",
       "...                                                  ...     ...   \n",
       "15927  I/O 2019 | Your Data Stays on Your Phone: Goog...  blyrbf   \n",
       "15928    Japan aims to produce 250,000 AI experts a year  b7yql0   \n",
       "15929  Why AI progress is faster than Moore’s Law — t...  b229a0   \n",
       "15930  Introducing GPipe, an Open Source Library for ...  azh242   \n",
       "15931  AI is not “magic dust” for your company, says ...  9vkwbw   \n",
       "\n",
       "                   redditor  num_upvotes    subreddit  \\\n",
       "0                da_chosen1         2892  datascience   \n",
       "1            MrBurritoQuest         2638  datascience   \n",
       "2      ExecutiveFingerblast         2498  datascience   \n",
       "3                      None         2313  datascience   \n",
       "4               VeryOddEvey         2226  datascience   \n",
       "...                     ...          ...          ...   \n",
       "15927               Yuqing7           50   artificial   \n",
       "15928              shaunlgs           53   artificial   \n",
       "15929             caternoon           53   artificial   \n",
       "15930       WebHostingSaver           54   artificial   \n",
       "15931                mr_j_b           53   artificial   \n",
       "\n",
       "                                                     url  num_comments  \\\n",
       "0                    https://i.redd.it/0c9louclfrl41.jpg            58   \n",
       "1      https://www.reddit.com/r/datascience/comments/...           262   \n",
       "2                    https://i.redd.it/e292g50m4u241.jpg           136   \n",
       "3                    https://i.redd.it/vh0ey1fgsm841.jpg           227   \n",
       "4                    https://i.redd.it/m99e3svtpqp41.jpg            43   \n",
       "...                                                  ...           ...   \n",
       "15927  https://medium.com/syncedreview/i-o-2019-your-...            10   \n",
       "15928  https://asia.nikkei.com/Economy/Japan-aims-to-...            11   \n",
       "15929  https://hackernoon.com/the-age-of-the-algorith...            39   \n",
       "15930  https://ai.googleblog.com/2019/03/introducing-...             0   \n",
       "15931  https://www.technologyreview.com/s/612394/ai-i...             7   \n",
       "\n",
       "               created_on                                               body  \\\n",
       "0     2020-03-10 16:26:29                                                      \n",
       "1     2020-07-10 17:15:31  I've been lurking on this sub for a while now ...   \n",
       "2     2019-12-06 05:16:05                                                      \n",
       "3     2020-01-05 00:23:50                                                      \n",
       "4     2020-03-30 18:17:40                                                      \n",
       "...                   ...                                                ...   \n",
       "15927 2019-05-08 14:18:50                                                      \n",
       "15928 2019-04-01 20:31:45                                                      \n",
       "15929 2019-03-17 19:40:56                                                      \n",
       "15930 2019-03-11 05:31:48                                                      \n",
       "15931 2018-11-10 04:03:24                                                      \n",
       "\n",
       "       upvote_ratio  over_18 link_flair_text edited  \n",
       "0              0.98    False            None  False  \n",
       "1              0.98    False      Discussion  False  \n",
       "2              0.98    False            None  False  \n",
       "3              0.97    False      Fun/Trivia  False  \n",
       "4              0.98    False      Fun/Trivia  False  \n",
       "...             ...      ...             ...    ...  \n",
       "15927          0.91    False            None  False  \n",
       "15928          0.88    False            None  False  \n",
       "15929          0.90    False            None  False  \n",
       "15930          0.93    False            None  False  \n",
       "15931          0.88    False            None  False  \n",
       "\n",
       "[15932 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-25T10:25:29.621837Z",
     "start_time": "2020-08-25T10:25:28.915577Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('machine_learning_and_data_science_subreddit_data.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
