{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Posts Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape data from the reddit, first of all you need to validate your self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:02:51.789042Z",
     "start_time": "2020-09-25T06:02:50.052078Z"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:02:51.816003Z",
     "start_time": "2020-09-25T06:02:51.810015Z"
    }
   },
   "outputs": [],
   "source": [
    "# chenge this\n",
    "my_client_id = 'Personal_Use_Script'\n",
    "my_client_secret = 'Client_Secret_Key'\n",
    "my_user_agent = 'Reddit_App_Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:02:52.274322Z",
     "start_time": "2020-09-25T06:02:51.875842Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=my_client_id, \\\n",
    "                     client_secret=my_client_secret, \\\n",
    "                     user_agent=my_user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:02:52.294796Z",
     "start_time": "2020-09-25T06:02:52.285268Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = {\"title\":[], \"id\":[], \"redditor\":[], \"num_upvotes\":[], \\\n",
    "             \"subreddit\":[], \"url\":[], \"num_comments\": [],\\\n",
    "             \"created_on\": [], \"body\":[], \"upvote_ratio\":[], \"over_18\":[],\\\n",
    "             \"link_flair_text\":[], \"edited\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:02:52.353192Z",
     "start_time": "2020-09-25T06:02:52.343287Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_posts(subreddit_name):\n",
    "    subreddit= reddit.subreddit(subreddit_name).top(limit=1000)\n",
    "    for submission in subreddit:\n",
    "        data_dict[\"title\"].append(submission.title)\n",
    "        data_dict[\"num_upvotes\"].append(submission.score)\n",
    "        data_dict[\"id\"].append(submission.id)\n",
    "        data_dict[\"subreddit\"].append(submission.subreddit)\n",
    "        data_dict[\"url\"].append(submission.url)\n",
    "        data_dict[\"num_comments\"].append(submission.num_comments)\n",
    "        data_dict[\"created_on\"].append(submission.created)\n",
    "        data_dict[\"body\"].append(submission.selftext)\n",
    "        data_dict[\"upvote_ratio\"].append(submission.upvote_ratio)\n",
    "        data_dict[\"over_18\"].append(submission.over_18)\n",
    "        data_dict[\"link_flair_text\"].append(submission.link_flair_text)\n",
    "        data_dict[\"edited\"].append(submission.edited)\n",
    "        data_dict[\"redditor\"].append(submission.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:03:02.097418Z",
     "start_time": "2020-09-25T06:03:02.091917Z"
    }
   },
   "outputs": [],
   "source": [
    "subreddits= ['datascience', 'MachineLearning', 'learnmachinelearning', \n",
    "             'LanguageTechnology', 'deeplearning', 'datasets', 'visualization',\n",
    "             'dataisbeautiful', 'learnpython', 'MLQuestions', 'DataVizRequests',\n",
    "             'statistics', 'SQL', 'neuralnetworks', 'mlpapers', 'MachinesLearn',\n",
    "             'datacleaning', 'artificial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:07:58.617044Z",
     "start_time": "2020-09-25T06:03:02.308549Z"
    }
   },
   "outputs": [],
   "source": [
    "for subreddit in subreddits:\n",
    "    get_posts(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:07:59.396580Z",
     "start_time": "2020-09-25T06:07:59.278083Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:08:00.236709Z",
     "start_time": "2020-09-25T06:08:00.192102Z"
    }
   },
   "outputs": [],
   "source": [
    "data['created_on'] = data['created_on'].apply(lambda x: dt.datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:08:00.962830Z",
     "start_time": "2020-09-25T06:08:00.900602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>redditor</th>\n",
       "      <th>num_upvotes</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_on</th>\n",
       "      <th>body</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>over_18</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Itâ€™s never too early</td>\n",
       "      <td>fg73za</td>\n",
       "      <td>da_chosen1</td>\n",
       "      <td>2913</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/0c9louclfrl41.jpg</td>\n",
       "      <td>59</td>\n",
       "      <td>2020-03-10 16:26:29</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shout Out to All the Mediocre Data Scientists ...</td>\n",
       "      <td>hohvgq</td>\n",
       "      <td>MrBurritoQuest</td>\n",
       "      <td>2787</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>264</td>\n",
       "      <td>2020-07-10 17:15:31</td>\n",
       "      <td>I've been lurking on this sub for a while now ...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imposter Syndrome is a problem for me and I th...</td>\n",
       "      <td>e6iy5o</td>\n",
       "      <td>ExecutiveFingerblast</td>\n",
       "      <td>2498</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/e292g50m4u241.jpg</td>\n",
       "      <td>135</td>\n",
       "      <td>2019-12-06 05:16:05</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True that</td>\n",
       "      <td>ejvao9</td>\n",
       "      <td>None</td>\n",
       "      <td>2309</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/vh0ey1fgsm841.jpg</td>\n",
       "      <td>223</td>\n",
       "      <td>2020-01-05 00:23:50</td>\n",
       "      <td></td>\n",
       "      <td>0.97</td>\n",
       "      <td>False</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graph of graph analysis</td>\n",
       "      <td>frkgr7</td>\n",
       "      <td>VeryOddEvey</td>\n",
       "      <td>2254</td>\n",
       "      <td>datascience</td>\n",
       "      <td>https://i.redd.it/m99e3svtpqp41.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>2020-03-30 18:17:40</td>\n",
       "      <td></td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15947</th>\n",
       "      <td>New AI platforms learn to predict and prevent ...</td>\n",
       "      <td>5zxhzt</td>\n",
       "      <td>Portis403</td>\n",
       "      <td>56</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://www.wired.com/2017/03/artificial-intel...</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-03-18 02:45:06</td>\n",
       "      <td></td>\n",
       "      <td>0.91</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15948</th>\n",
       "      <td>The IEEE has released the 1st draft of their A...</td>\n",
       "      <td>5i8sq2</td>\n",
       "      <td>BerickCook</td>\n",
       "      <td>57</td>\n",
       "      <td>artificial</td>\n",
       "      <td>http://standards.ieee.org/develop/indconn/ec/e...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-14 18:47:06</td>\n",
       "      <td></td>\n",
       "      <td>0.94</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15949</th>\n",
       "      <td>White House: Preparing for the Future of Artif...</td>\n",
       "      <td>4hqhbi</td>\n",
       "      <td>ScientiaOmniaVincit</td>\n",
       "      <td>54</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://www.whitehouse.gov/blog/2016/05/03/pre...</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-05-04 10:54:02</td>\n",
       "      <td></td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15950</th>\n",
       "      <td>Google: Tensorflow â€” Neural Network Playground</td>\n",
       "      <td>4fc8cs</td>\n",
       "      <td>king_of_the_universe</td>\n",
       "      <td>54</td>\n",
       "      <td>artificial</td>\n",
       "      <td>http://playground.tensorflow.org</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-04-19 04:28:28</td>\n",
       "      <td></td>\n",
       "      <td>0.94</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15951</th>\n",
       "      <td>What is the most astonishing AI application th...</td>\n",
       "      <td>3mp6cs</td>\n",
       "      <td>FunnyParrot</td>\n",
       "      <td>57</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://www.reddit.com/r/artificial/comments/3...</td>\n",
       "      <td>16</td>\n",
       "      <td>2015-09-29 03:16:12</td>\n",
       "      <td></td>\n",
       "      <td>0.96</td>\n",
       "      <td>False</td>\n",
       "      <td>opinion</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15952 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      id  \\\n",
       "0                                   Itâ€™s never too early  fg73za   \n",
       "1      Shout Out to All the Mediocre Data Scientists ...  hohvgq   \n",
       "2      Imposter Syndrome is a problem for me and I th...  e6iy5o   \n",
       "3                                              True that  ejvao9   \n",
       "4                                Graph of graph analysis  frkgr7   \n",
       "...                                                  ...     ...   \n",
       "15947  New AI platforms learn to predict and prevent ...  5zxhzt   \n",
       "15948  The IEEE has released the 1st draft of their A...  5i8sq2   \n",
       "15949  White House: Preparing for the Future of Artif...  4hqhbi   \n",
       "15950     Google: Tensorflow â€” Neural Network Playground  4fc8cs   \n",
       "15951  What is the most astonishing AI application th...  3mp6cs   \n",
       "\n",
       "                   redditor  num_upvotes    subreddit  \\\n",
       "0                da_chosen1         2913  datascience   \n",
       "1            MrBurritoQuest         2787  datascience   \n",
       "2      ExecutiveFingerblast         2498  datascience   \n",
       "3                      None         2309  datascience   \n",
       "4               VeryOddEvey         2254  datascience   \n",
       "...                     ...          ...          ...   \n",
       "15947             Portis403           56   artificial   \n",
       "15948            BerickCook           57   artificial   \n",
       "15949   ScientiaOmniaVincit           54   artificial   \n",
       "15950  king_of_the_universe           54   artificial   \n",
       "15951           FunnyParrot           57   artificial   \n",
       "\n",
       "                                                     url  num_comments  \\\n",
       "0                    https://i.redd.it/0c9louclfrl41.jpg            59   \n",
       "1      https://www.reddit.com/r/datascience/comments/...           264   \n",
       "2                    https://i.redd.it/e292g50m4u241.jpg           135   \n",
       "3                    https://i.redd.it/vh0ey1fgsm841.jpg           223   \n",
       "4                    https://i.redd.it/m99e3svtpqp41.jpg            42   \n",
       "...                                                  ...           ...   \n",
       "15947  https://www.wired.com/2017/03/artificial-intel...             5   \n",
       "15948  http://standards.ieee.org/develop/indconn/ec/e...             0   \n",
       "15949  https://www.whitehouse.gov/blog/2016/05/03/pre...            10   \n",
       "15950                   http://playground.tensorflow.org            12   \n",
       "15951  https://www.reddit.com/r/artificial/comments/3...            16   \n",
       "\n",
       "               created_on                                               body  \\\n",
       "0     2020-03-10 16:26:29                                                      \n",
       "1     2020-07-10 17:15:31  I've been lurking on this sub for a while now ...   \n",
       "2     2019-12-06 05:16:05                                                      \n",
       "3     2020-01-05 00:23:50                                                      \n",
       "4     2020-03-30 18:17:40                                                      \n",
       "...                   ...                                                ...   \n",
       "15947 2017-03-18 02:45:06                                                      \n",
       "15948 2016-12-14 18:47:06                                                      \n",
       "15949 2016-05-04 10:54:02                                                      \n",
       "15950 2016-04-19 04:28:28                                                      \n",
       "15951 2015-09-29 03:16:12                                                      \n",
       "\n",
       "       upvote_ratio  over_18 link_flair_text edited  \n",
       "0              0.98    False            None  False  \n",
       "1              0.98    False      Discussion  False  \n",
       "2              0.98    False            None  False  \n",
       "3              0.97    False      Fun/Trivia  False  \n",
       "4              0.98    False      Fun/Trivia  False  \n",
       "...             ...      ...             ...    ...  \n",
       "15947          0.91    False            None  False  \n",
       "15948          0.94    False            None  False  \n",
       "15949          0.95    False            None  False  \n",
       "15950          0.94    False            None  False  \n",
       "15951          0.96    False         opinion  False  \n",
       "\n",
       "[15952 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:08:01.964926Z",
     "start_time": "2020-09-25T06:08:01.629249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past reddit posts: (31943, 13)\n"
     ]
    }
   ],
   "source": [
    "reddit_old_data = pd.read_csv(\"machine_learning_and_data_science_subreddit_data.csv\")\n",
    "print(f\"past reddit posts: {reddit_old_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:08:02.814372Z",
     "start_time": "2020-09-25T06:08:02.614634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new reddit posts: 15952 past reddit posts: 31943 all reddit posts: 47895\n"
     ]
    }
   ],
   "source": [
    "reddit_all_df = pd.concat([reddit_old_data, data], axis=0)\n",
    "print(f\"new reddit posts: {data.shape[0]} past reddit posts: {reddit_old_data.shape[0]} all reddit posts: {reddit_all_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:08:03.813607Z",
     "start_time": "2020-09-25T06:08:03.479553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all reddit posts: (32042, 13)\n"
     ]
    }
   ],
   "source": [
    "reddit_all_df.drop_duplicates(subset = [\"title\", \"id\", \"redditor\", \"subreddit\"], inplace=True)\n",
    "print(f\"all reddit posts: {reddit_all_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T06:08:05.379688Z",
     "start_time": "2020-09-25T06:08:04.442857Z"
    }
   },
   "outputs": [],
   "source": [
    "reddit_all_df.to_csv('machine_learning_and_data_science_subreddit_data.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
